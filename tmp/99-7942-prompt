<DIRECTIONS>
haz test con x_train ficticios comparando la salida de un predict tensorflow con mi nn, observa el formato que retorno las predicciones en @atom/nn.py 

</DIRECTIONS>
<Context>
You receive a selection in neovim that you need to replace with new code.
The selection's contents may contain notes, incorporate the notes every time if there are some.
consider the context of the selection and what you are suppose to be implementing
<SELECTION_LOCATION>
range(point(83,4),point(84,9))
</SELECTION_LOCATION>
<SELECTION_CONTENT>
 def test_predict(self):
        
</SELECTION_CONTENT>
<FILE_CONTAINING_SELECTION>
import pytest
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
import numpy as np
from atom.nn import Dense,Sequential


class TestDense:
    def test_init_validations(self):
        with pytest.raises(ValueError):
             Dense(units=2,activation='foo')
            
        valid_dense = Dense(units=10,activation='sigmoid')
        assert valid_dense
    
    def test_build(self):
        
        layer = Dense(units=10,activation='sigmoid')
        with pytest.raises(ValueError):
            layer.build(input_shape=(3,3,100))

        layer.build(input_shape=(1000,400))
        
        assert layer.w.shape == (400,10)
        assert layer.b.shape == (1,10)


    def test_set_weights(self):
         with pytest.raises(ValueError):
            layer = Dense(units=3,activation='relu')
            layer.set_weights(np.array([300,200]),np.ndarray([20,20]))
            


class TestSequential:
    def test_post_init(self):
        model = Sequential([
            Dense(units=10, activation='relu',input_shape=(1000,400)),
            Dense(units=15, activation='relu'),
            Dense(units=1, activation='sigmoid')
        ]) 

        w1_shape, b1_shape = (400, 10), (1, 10)
        w2_shape, b2_shape = (10, 15), (1, 15)
        w3_shape, b3_shape = (15, 1), (1, 1)
        
        assert model[0].w.shape == w1_shape
        assert model[0].b.shape == b1_shape
        assert model[1].w.shape == w2_shape
        assert model[1].b.shape == b2_shape
        assert model[2].w.shape == w3_shape
        assert model[2].b.shape == b3_shape

    def test_build(self):
        
        x_train = np.random.randn(1000,400)
        model = Sequential([
            Dense(units=10, activation='relu'),
            Dense(units=15, activation='relu'),
            Dense(units=1, activation='relu')
        ]) 

        for layer in model:
            assert not hasattr(layer, 'w') or layer.w is None 
            
        model.build(input_shape=x_train.shape)
        
        w1_shape, b1_shape = (400, 10), (1, 10)
        w2_shape, b2_shape = (10, 15), (1, 15)
        w3_shape, b3_shape = (15, 1), (1, 1)

        assert model[0].w.shape == w1_shape
        assert model[0].b.shape == b1_shape
        assert model[1].w.shape == w2_shape
        assert model[1].b.shape == b2_shape
        assert model[2].w.shape == w3_shape
        assert model[2].b.shape == b3_shape 

        model.predict(x_train)


    def test_predict(self):
        
</FILE_CONTAINING_SELECTION>

</Context>

```py
-- atom/nn.py
import numpy as np
from dataclasses import dataclass,field
from typing import Callable
from atom.activations import sigmoid,relu,linear
from typing import Optional

@dataclass
class BinaryCrossentropy:
    y_hat:np.ndarray
    y:np.ndarray

    def compute_loss(self):return -self.y*np.log(self.y_hat) - (1-self.y) * np.log(1-self.y_hat)
    
    def compute_cost(self):return np.mean(self.compute_loss())


class Dense:

    ACTIVATIONS = {'sigmoid':sigmoid,
                   'relu':relu,
                   'linear':linear}
    
    def __init__(self,
                 units: int,
                 activation: str,
                 input_shape: tuple[int,int] | None = None,
                 ):
        
        if not  activation in self.ACTIVATIONS:
            raise ValueError("Activation not allowed")
    
        self.units = units
        self.input_shape = input_shape
        self.activation_function: Callable[[np.ndarray],np.ndarray] = self.ACTIVATIONS[activation]
        self.w: np.ndarray | None = None
        self.b: np.ndarray | None = None
        
        if self.input_shape:
            self._init_w_b()
     
    def _init_w_b(self, w: np.ndarray | None = None, b: np.ndarray | None = None):
        if not self.input_shape:
            raise ValueError("Unknown input shape")
        self.w = w if w is not None else np.random.randn(self.input_shape[1], self.units) * 0.01
        self.b = b if b is not None else np.zeros((1, self.units))
  

    def set_weights(self,w: np.ndarray,b: np.ndarray):
        self._init_w_b(w=w,b=b)

            
    def build(self,input_shape: tuple[int,int]):
        if not isinstance(input_shape,tuple) or len(input_shape) != 2:
            raise ValueError("Invalid input shape")
        self.input_shape = input_shape
        self._init_w_b()    
        

@dataclass
class Sequential:
    layers: list[Dense]

    def _set_weights_layers(self,input_shape: tuple[int,int]):
        current_dim = input_shape[-1]
        for layer in self.layers:
            layer.build((input_shape[0],current_dim))
            current_dim = layer.units

            
    def __post_init__(self):
        if getattr(self.layers[0],"input_shape",None) is not None:
            input_shape = self.layers[0].input_shape
            self._set_weights_layers(input_shape)


    def __getitem__(self,position: int):
        return self.layers[position]

    def __iter__(self):
        return iter(self.layers)
    
    
    def build(self,input_shape: tuple)->None:
        self._set_weights_layers(input_shape)
            
    def predict(self,x:np.ndarray):
        a: np.ndarray = x
        for layer in self.layers:
            z = (a @ layer.w) + layer.b
            print(z.shape)
            a = layer.activation_function(z)
        return a

   
    def set_weights(self,weights:list[np.ndarray]):
        assert len(weights) == 2 * len(self.layers)
        for index,layer in enumerate(self.layers):
            layer.w,layer.b = weights[index * 2],weights[index * 2 + 1]


    

    

```
<MustObey>
NEVER alter any file other than TEMP_FILE.
never provide the requested changes as conversational output. Return only the code.
ONLY provide requested changes by writing the change to TEMP_FILE

never attempt to read TEMP_FILE.
It is purely for output.
Previous contents, which may not exist, can be written over without worry
After writing TEMP_FILE once you should be done.  Be done and end the session.

</MustObey>
<TEMP_FILE>/home/felipe/atom/tmp/99-7942</TEMP_FILE>